(set-info :origin "NTS benchmark converted to SMT-LIB2 using Eldarica (http://lara.epfl.ch/w/eldarica)")
(set-logic HORN)
(declare-fun INV1 ((_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32) (_ BitVec 32)) Bool)
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)))(=> (and (and (and (and (and (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32)) (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd A (bvneg (_ bv1 32))) (_ bv0 32)))) (not (= H (_ bv0 32)))) (INV1 A B C D H I F G)) (= F G)) (INV1 A B C D E D F G))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32)) (= (bvadd D (_ bv2 32)) F)) (bvsge (bvadd (bvsub (_ bv1000 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv100 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd A (bvneg (_ bv1 32))) (_ bv0 32)))) (not (= I (_ bv0 32)))) (INV1 A B C D I J G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (= (bvadd I (_ bv4 32)) D) (bvsge (bvadd (bvsub (bvmul (_ bv10000 32) C) (bvadd J (bvneg (_ bv10000 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd J (bvmul (bvneg (_ bv10000 32)) C)) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv10000 32) J) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv1000 32) J) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv100 32) J) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv10 32) J) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd A (bvneg (_ bv1 32))) (_ bv0 32)))) (not (= E (_ bv0 32)))) (INV1 A B J I E F G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32)) (= (bvadd D (_ bv3 32)) F)) (bvsge (bvadd (bvsub (_ bv10000 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv1000 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv100 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd A (bvneg (_ bv1 32))) (_ bv0 32)))) (not (= I (_ bv0 32)))) (INV1 A B C D I J G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)))(=> (and (and (and (and (and (and (and (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32)) (= (bvadd D (_ bv1 32)) F)) (bvsge (bvadd (bvsub (_ bv100 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd A (bvneg (_ bv1 32))) (_ bv0 32)))) (not (= I (_ bv0 32)))) (INV1 A B C D I J G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (= (bvadd H (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd I (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd I (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (not (bvsge (bvadd J (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J) (bvadd I (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd I (bvmul (bvneg (_ bv10 32)) J)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd I (bvneg (_ bv1 32))) (_ bv0 32))) (not (= K (_ bv0 32)))) (INV1 I H C D K L F G)) (= F G)) (INV1 A B C D E D F G))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)) (S (_ BitVec 32)) (T (_ BitVec 32)) (U (_ BitVec 32)) (V (_ BitVec 32)) (W (_ BitVec 32)) (X (_ BitVec 32)) (Y (_ BitVec 32)) (Z (_ BitVec 32)) (A1 (_ BitVec 32)) (B1 (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd (bvadd H (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd I (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) I) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) J)) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) I)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) L) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) L)) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) M) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) M)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (not (bvsge (bvadd P (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd Q (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Q) (bvadd R (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) R) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) R)) (_ bv0 32))) (bvsge (bvadd S (bvmul (bvneg (_ bv10 32)) Q)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) S) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) S)) (_ bv0 32))) (bvsge (bvadd T (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) T) (bvadd U (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) U) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) U)) (_ bv0 32))) (bvsge (bvadd V (bvmul (bvneg (_ bv10 32)) T)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) V) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) V)) (_ bv0 32))) (bvsge (bvadd W (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) W) (bvadd X (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) X) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) X)) (_ bv0 32))) (bvsge (bvadd Y (bvmul (bvneg (_ bv10 32)) W)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Y) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) Y)) (_ bv0 32))) (bvsge (bvadd Z (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Z) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) Z)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvneg (_ bv1 32))) (_ bv0 32))) (not (= A1 (_ bv0 32)))) (INV1 K H C D A1 B1 F G)) (= F G)) (INV1 A B C D E D F G))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)) (S (_ BitVec 32)) (T (_ BitVec 32)) (U (_ BitVec 32)) (V (_ BitVec 32)) (W (_ BitVec 32)) (X (_ BitVec 32)) (Y (_ BitVec 32)) (Z (_ BitVec 32)) (A1 (_ BitVec 32)) (B1 (_ BitVec 32)) (C1 (_ BitVec 32)) (D1 (_ BitVec 32)) (E1 (_ BitVec 32)) (F1 (_ BitVec 32)) (G1 (_ BitVec 32)) (H1 (_ BitVec 32)) (I1 (_ BitVec 32)) (J1 (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd (bvadd (bvadd H (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd I (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) I) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) K) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) K)) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) J)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) M) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) M)) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) I)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd P (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (bvsge (bvadd Q (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Q) (bvadd R (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) R) (bvadd S (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) S) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) S)) (_ bv0 32))) (bvsge (bvadd T (bvmul (bvneg (_ bv10 32)) R)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) T) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) T)) (_ bv0 32))) (bvsge (bvadd U (bvmul (bvneg (_ bv10 32)) Q)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) U) (bvadd V (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) V) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) V)) (_ bv0 32))) (bvsge (bvadd W (bvmul (bvneg (_ bv10 32)) U)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) W) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) W)) (_ bv0 32))) (bvsge (bvadd X (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) X) (bvadd Y (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Y) (bvadd Z (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Z) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) Z)) (_ bv0 32))) (bvsge (bvadd A1 (bvmul (bvneg (_ bv10 32)) Y)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A1) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) A1)) (_ bv0 32))) (bvsge (bvadd B1 (bvmul (bvneg (_ bv10 32)) X)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) B1) (bvadd C1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) C1) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) C1)) (_ bv0 32))) (bvsge (bvadd D1 (bvmul (bvneg (_ bv10 32)) B1)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) D1) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) D1)) (_ bv0 32))) (bvsge (bvadd E1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) E1) (bvadd F1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) F1) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) F1)) (_ bv0 32))) (bvsge (bvadd G1 (bvmul (bvneg (_ bv10 32)) E1)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) G1) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) G1)) (_ bv0 32))) (bvsge (bvadd H1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) H1) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) H1)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvneg (_ bv1 32))) (_ bv0 32))) (not (= I1 (_ bv0 32)))) (INV1 L H C D I1 J1 F G)) (= F G)) (INV1 A B C D E D F G))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd H (_ bv1 32)) (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd I (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) I) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd J (bvmul (bvneg (_ bv10 32)) I)) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) K) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd J (bvmul (bvneg (_ bv10 32)) K)) (_ bv0 32))) (not (bvsge (bvadd L (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) L) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) M) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd J (bvmul (bvneg (_ bv10 32)) M)) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) L)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd J (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd O (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd J (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd J (bvneg (_ bv1 32))) (_ bv0 32))) (not (= P (_ bv0 32)))) (INV1 J H C D P Q F G)) (= F G)) (INV1 A B C D E D F G))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd I (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (= (bvadd D (_ bv2 32)) F)) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd J (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (not (bvsge (bvadd K (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) K) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd J (bvmul (bvneg (_ bv10 32)) K)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv1000 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv100 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd J (bvneg (_ bv1 32))) (_ bv0 32))) (not (= L (_ bv0 32)))) (INV1 J I C D L M G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)) (S (_ BitVec 32)) (T (_ BitVec 32)) (U (_ BitVec 32)) (V (_ BitVec 32)) (W (_ BitVec 32)) (X (_ BitVec 32)) (Y (_ BitVec 32)) (Z (_ BitVec 32)) (A1 (_ BitVec 32)) (B1 (_ BitVec 32)) (C1 (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd (bvadd I (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (= (bvadd D (_ bv2 32)) F)) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) K) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) K)) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) J)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) M) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) M)) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd P (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (not (bvsge (bvadd Q (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Q) (bvadd R (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) R) (bvadd S (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) S) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) S)) (_ bv0 32))) (bvsge (bvadd T (bvmul (bvneg (_ bv10 32)) R)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) T) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) T)) (_ bv0 32))) (bvsge (bvadd U (bvmul (bvneg (_ bv10 32)) Q)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) U) (bvadd V (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) V) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) V)) (_ bv0 32))) (bvsge (bvadd W (bvmul (bvneg (_ bv10 32)) U)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) W) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) W)) (_ bv0 32))) (bvsge (bvadd X (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) X) (bvadd Y (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Y) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) Y)) (_ bv0 32))) (bvsge (bvadd Z (bvmul (bvneg (_ bv10 32)) X)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Z) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) Z)) (_ bv0 32))) (bvsge (bvadd A1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A1) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) A1)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv1000 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv100 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd L (bvneg (_ bv1 32))) (_ bv0 32))) (not (= B1 (_ bv0 32)))) (INV1 L I C D B1 C1 G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)) (S (_ BitVec 32)) (T (_ BitVec 32)) (U (_ BitVec 32)) (V (_ BitVec 32)) (W (_ BitVec 32)) (X (_ BitVec 32)) (Y (_ BitVec 32)) (Z (_ BitVec 32)) (A1 (_ BitVec 32)) (B1 (_ BitVec 32)) (C1 (_ BitVec 32)) (D1 (_ BitVec 32)) (E1 (_ BitVec 32)) (F1 (_ BitVec 32)) (G1 (_ BitVec 32)) (H1 (_ BitVec 32)) (I1 (_ BitVec 32)) (J1 (_ BitVec 32)) (K1 (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd (bvadd (bvadd I (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (= (bvadd D (_ bv2 32)) F)) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) K) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) L) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) L)) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) K)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) J)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd P (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (bvsge (bvadd Q (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Q) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) Q)) (_ bv0 32))) (bvsge (bvadd R (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) R) (bvadd S (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) S) (bvadd T (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) T) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) T)) (_ bv0 32))) (bvsge (bvadd U (bvmul (bvneg (_ bv10 32)) S)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) U) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) U)) (_ bv0 32))) (bvsge (bvadd V (bvmul (bvneg (_ bv10 32)) R)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) V) (bvadd W (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) W) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) W)) (_ bv0 32))) (bvsge (bvadd X (bvmul (bvneg (_ bv10 32)) V)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) X) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) X)) (_ bv0 32))) (bvsge (bvadd Y (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Y) (bvadd Z (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Z) (bvadd A1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) A1)) (_ bv0 32))) (bvsge (bvadd B1 (bvmul (bvneg (_ bv10 32)) Z)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) B1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) B1)) (_ bv0 32))) (bvsge (bvadd C1 (bvmul (bvneg (_ bv10 32)) Y)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) C1) (bvadd D1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) D1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) D1)) (_ bv0 32))) (bvsge (bvadd E1 (bvmul (bvneg (_ bv10 32)) C1)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) E1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) E1)) (_ bv0 32))) (bvsge (bvadd F1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) F1) (bvadd G1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) G1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) G1)) (_ bv0 32))) (bvsge (bvadd H1 (bvmul (bvneg (_ bv10 32)) F1)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) H1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) H1)) (_ bv0 32))) (bvsge (bvadd I1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) I1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) I1)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv1000 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv100 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd M (bvneg (_ bv1 32))) (_ bv0 32))) (not (= J1 (_ bv0 32)))) (INV1 M I C D J1 K1 G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd I (_ bv1 32)) (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (= (bvadd D (_ bv2 32)) F)) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) J)) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) L) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) L)) (_ bv0 32))) (not (bvsge (bvadd M (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) M) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) M)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd P (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv1000 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv100 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd K (bvneg (_ bv1 32))) (_ bv0 32))) (not (= Q (_ bv0 32)))) (INV1 K I C D Q R G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd I (_ bv1 32)) (_ bv1 32)) B) (= (bvadd J (_ bv4 32)) D)) (bvsge (bvadd (bvsub (bvmul (_ bv10000 32) C) (bvadd K (bvneg (_ bv10000 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10000 32)) C)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) L) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) L)) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (not (bvsge (bvadd O (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd P (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (bvsge (bvadd Q (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Q) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) Q)) (_ bv0 32))) (bvsge (bvadd R (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) R) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) R)) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv10000 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv1000 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv100 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv10 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd M (bvneg (_ bv1 32))) (_ bv0 32))) (not (= E (_ bv0 32)))) (INV1 M I K J E F G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)) (S (_ BitVec 32)) (T (_ BitVec 32)) (U (_ BitVec 32)) (V (_ BitVec 32)) (W (_ BitVec 32)) (X (_ BitVec 32)) (Y (_ BitVec 32)) (Z (_ BitVec 32)) (A1 (_ BitVec 32)) (B1 (_ BitVec 32)) (C1 (_ BitVec 32)) (D1 (_ BitVec 32)) (E1 (_ BitVec 32)) (F1 (_ BitVec 32)) (G1 (_ BitVec 32)) (H1 (_ BitVec 32)) (I1 (_ BitVec 32)) (J1 (_ BitVec 32)) (K1 (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd (bvadd (bvadd I (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) B) (= (bvadd J (_ bv4 32)) D)) (bvsge (bvadd (bvsub (bvmul (_ bv10000 32) C) (bvadd K (bvneg (_ bv10000 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10000 32)) C)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) L) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) M) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd P (bvmul (bvneg (_ bv10 32)) M)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (bvsge (bvadd Q (bvmul (bvneg (_ bv10 32)) L)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Q) (bvadd R (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) R) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) R)) (_ bv0 32))) (bvsge (bvadd S (bvmul (bvneg (_ bv10 32)) Q)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) S) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) S)) (_ bv0 32))) (bvsge (bvadd T (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) T) (bvadd U (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) U) (bvadd V (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) V) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) V)) (_ bv0 32))) (bvsge (bvadd W (bvmul (bvneg (_ bv10 32)) U)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) W) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) W)) (_ bv0 32))) (bvsge (bvadd X (bvmul (bvneg (_ bv10 32)) T)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) X) (bvadd Y (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Y) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) Y)) (_ bv0 32))) (bvsge (bvadd Z (bvmul (bvneg (_ bv10 32)) X)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Z) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) Z)) (_ bv0 32))) (bvsge (bvadd A1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A1) (bvadd B1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) B1) (bvadd C1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) C1) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) C1)) (_ bv0 32))) (bvsge (bvadd D1 (bvmul (bvneg (_ bv10 32)) B1)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) D1) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) D1)) (_ bv0 32))) (bvsge (bvadd E1 (bvmul (bvneg (_ bv10 32)) A1)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) E1) (bvadd F1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) F1) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) F1)) (_ bv0 32))) (bvsge (bvadd G1 (bvmul (bvneg (_ bv10 32)) E1)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) G1) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) G1)) (_ bv0 32))) (bvsge (bvadd H1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) H1) (bvadd I1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) I1) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) I1)) (_ bv0 32))) (bvsge (bvadd J1 (bvmul (bvneg (_ bv10 32)) H1)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J1) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) J1)) (_ bv0 32))) (bvsge (bvadd K1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) K1) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) K1)) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv10000 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv1000 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv100 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv10 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd O (bvneg (_ bv1 32))) (_ bv0 32))) (not (= E (_ bv0 32)))) (INV1 O I K J E F G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)) (S (_ BitVec 32)) (T (_ BitVec 32)) (U (_ BitVec 32)) (V (_ BitVec 32)) (W (_ BitVec 32)) (X (_ BitVec 32)) (Y (_ BitVec 32)) (Z (_ BitVec 32)) (A1 (_ BitVec 32)) (B1 (_ BitVec 32)) (C1 (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd (bvadd I (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) B) (= (bvadd J (_ bv4 32)) D)) (bvsge (bvadd (bvsub (bvmul (_ bv10000 32) C) (bvadd K (bvneg (_ bv10000 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10000 32)) C)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) L) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) M) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) M)) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) L)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd P (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd Q (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Q) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) Q)) (_ bv0 32))) (bvsge (bvadd R (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) R) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) R)) (_ bv0 32))) (not (bvsge (bvadd S (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) S) (bvadd T (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) T) (bvadd U (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) U) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) U)) (_ bv0 32))) (bvsge (bvadd V (bvmul (bvneg (_ bv10 32)) T)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) V) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) V)) (_ bv0 32))) (bvsge (bvadd W (bvmul (bvneg (_ bv10 32)) S)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) W) (bvadd X (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) X) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) X)) (_ bv0 32))) (bvsge (bvadd Y (bvmul (bvneg (_ bv10 32)) W)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Y) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) Y)) (_ bv0 32))) (bvsge (bvadd Z (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Z) (bvadd A1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A1) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) A1)) (_ bv0 32))) (bvsge (bvadd B1 (bvmul (bvneg (_ bv10 32)) Z)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) B1) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) B1)) (_ bv0 32))) (bvsge (bvadd C1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) C1) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) C1)) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv10000 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv1000 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv100 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv10 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd N (bvneg (_ bv1 32))) (_ bv0 32))) (not (= E (_ bv0 32)))) (INV1 N I K J E F G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd I (_ bv1 32)) B) (= (bvadd J (_ bv4 32)) D)) (bvsge (bvadd (bvsub (bvmul (_ bv10000 32) C) (bvadd K (bvneg (_ bv10000 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10000 32)) C)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (not (bvsge (bvadd M (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) M) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) M)) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv10000 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv1000 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv100 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv10 32) K) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd L (bvneg (_ bv1 32))) (_ bv0 32))) (not (= E (_ bv0 32)))) (INV1 L I K J E F G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd I (_ bv1 32)) (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (= (bvadd D (_ bv3 32)) F)) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) J)) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) L) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) L)) (_ bv0 32))) (not (bvsge (bvadd M (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) M) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) M)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd P (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv10000 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv1000 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv100 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd K (bvneg (_ bv1 32))) (_ bv0 32))) (not (= Q (_ bv0 32)))) (INV1 K I C D Q R G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)) (S (_ BitVec 32)) (T (_ BitVec 32)) (U (_ BitVec 32)) (V (_ BitVec 32)) (W (_ BitVec 32)) (X (_ BitVec 32)) (Y (_ BitVec 32)) (Z (_ BitVec 32)) (A1 (_ BitVec 32)) (B1 (_ BitVec 32)) (C1 (_ BitVec 32)) (D1 (_ BitVec 32)) (E1 (_ BitVec 32)) (F1 (_ BitVec 32)) (G1 (_ BitVec 32)) (H1 (_ BitVec 32)) (I1 (_ BitVec 32)) (J1 (_ BitVec 32)) (K1 (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd (bvadd (bvadd I (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (= (bvadd D (_ bv3 32)) F)) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) K) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) L) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) L)) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) K)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) J)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd P (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (bvsge (bvadd Q (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Q) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) Q)) (_ bv0 32))) (bvsge (bvadd R (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) R) (bvadd S (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) S) (bvadd T (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) T) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) T)) (_ bv0 32))) (bvsge (bvadd U (bvmul (bvneg (_ bv10 32)) S)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) U) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) U)) (_ bv0 32))) (bvsge (bvadd V (bvmul (bvneg (_ bv10 32)) R)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) V) (bvadd W (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) W) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) W)) (_ bv0 32))) (bvsge (bvadd X (bvmul (bvneg (_ bv10 32)) V)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) X) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) X)) (_ bv0 32))) (bvsge (bvadd Y (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Y) (bvadd Z (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Z) (bvadd A1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) A1)) (_ bv0 32))) (bvsge (bvadd B1 (bvmul (bvneg (_ bv10 32)) Z)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) B1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) B1)) (_ bv0 32))) (bvsge (bvadd C1 (bvmul (bvneg (_ bv10 32)) Y)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) C1) (bvadd D1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) D1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) D1)) (_ bv0 32))) (bvsge (bvadd E1 (bvmul (bvneg (_ bv10 32)) C1)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) E1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) E1)) (_ bv0 32))) (bvsge (bvadd F1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) F1) (bvadd G1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) G1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) G1)) (_ bv0 32))) (bvsge (bvadd H1 (bvmul (bvneg (_ bv10 32)) F1)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) H1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) H1)) (_ bv0 32))) (bvsge (bvadd I1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) I1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) I1)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv10000 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv1000 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv100 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd M (bvneg (_ bv1 32))) (_ bv0 32))) (not (= J1 (_ bv0 32)))) (INV1 M I C D J1 K1 G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)) (S (_ BitVec 32)) (T (_ BitVec 32)) (U (_ BitVec 32)) (V (_ BitVec 32)) (W (_ BitVec 32)) (X (_ BitVec 32)) (Y (_ BitVec 32)) (Z (_ BitVec 32)) (A1 (_ BitVec 32)) (B1 (_ BitVec 32)) (C1 (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd (bvadd I (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (= (bvadd D (_ bv3 32)) F)) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) K) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) K)) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) J)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) M) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) M)) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd P (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (not (bvsge (bvadd Q (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Q) (bvadd R (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) R) (bvadd S (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) S) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) S)) (_ bv0 32))) (bvsge (bvadd T (bvmul (bvneg (_ bv10 32)) R)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) T) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) T)) (_ bv0 32))) (bvsge (bvadd U (bvmul (bvneg (_ bv10 32)) Q)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) U) (bvadd V (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) V) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) V)) (_ bv0 32))) (bvsge (bvadd W (bvmul (bvneg (_ bv10 32)) U)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) W) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) W)) (_ bv0 32))) (bvsge (bvadd X (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) X) (bvadd Y (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Y) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) Y)) (_ bv0 32))) (bvsge (bvadd Z (bvmul (bvneg (_ bv10 32)) X)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Z) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) Z)) (_ bv0 32))) (bvsge (bvadd A1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A1) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) A1)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv10000 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv1000 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv100 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd L (bvneg (_ bv1 32))) (_ bv0 32))) (not (= B1 (_ bv0 32)))) (INV1 L I C D B1 C1 G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd I (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (= (bvadd D (_ bv3 32)) F)) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd J (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (not (bvsge (bvadd K (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) K) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd J (bvmul (bvneg (_ bv10 32)) K)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv10000 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv1000 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv100 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (not (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd J (bvneg (_ bv1 32))) (_ bv0 32))) (not (= L (_ bv0 32)))) (INV1 J I C D L M G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd I (_ bv1 32)) (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (= (bvadd D (_ bv1 32)) F)) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) J)) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) L) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) L)) (_ bv0 32))) (not (bvsge (bvadd M (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) M) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) M)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd P (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv100 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd K (bvneg (_ bv1 32))) (_ bv0 32))) (not (= Q (_ bv0 32)))) (INV1 K I C D Q R G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)) (S (_ BitVec 32)) (T (_ BitVec 32)) (U (_ BitVec 32)) (V (_ BitVec 32)) (W (_ BitVec 32)) (X (_ BitVec 32)) (Y (_ BitVec 32)) (Z (_ BitVec 32)) (A1 (_ BitVec 32)) (B1 (_ BitVec 32)) (C1 (_ BitVec 32)) (D1 (_ BitVec 32)) (E1 (_ BitVec 32)) (F1 (_ BitVec 32)) (G1 (_ BitVec 32)) (H1 (_ BitVec 32)) (I1 (_ BitVec 32)) (J1 (_ BitVec 32)) (K1 (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd (bvadd (bvadd I (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (= (bvadd D (_ bv1 32)) F)) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) K) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) L) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) L)) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) K)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) J)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd P (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (bvsge (bvadd Q (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Q) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) Q)) (_ bv0 32))) (bvsge (bvadd R (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) R) (bvadd S (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) S) (bvadd T (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) T) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) T)) (_ bv0 32))) (bvsge (bvadd U (bvmul (bvneg (_ bv10 32)) S)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) U) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) U)) (_ bv0 32))) (bvsge (bvadd V (bvmul (bvneg (_ bv10 32)) R)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) V) (bvadd W (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) W) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) W)) (_ bv0 32))) (bvsge (bvadd X (bvmul (bvneg (_ bv10 32)) V)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) X) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) X)) (_ bv0 32))) (bvsge (bvadd Y (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Y) (bvadd Z (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Z) (bvadd A1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) A1)) (_ bv0 32))) (bvsge (bvadd B1 (bvmul (bvneg (_ bv10 32)) Z)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) B1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) B1)) (_ bv0 32))) (bvsge (bvadd C1 (bvmul (bvneg (_ bv10 32)) Y)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) C1) (bvadd D1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) D1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) D1)) (_ bv0 32))) (bvsge (bvadd E1 (bvmul (bvneg (_ bv10 32)) C1)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) E1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) E1)) (_ bv0 32))) (bvsge (bvadd F1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) F1) (bvadd G1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) G1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) G1)) (_ bv0 32))) (bvsge (bvadd H1 (bvmul (bvneg (_ bv10 32)) F1)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) H1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) H1)) (_ bv0 32))) (bvsge (bvadd I1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) I1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) I1)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv100 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd M (bvneg (_ bv1 32))) (_ bv0 32))) (not (= J1 (_ bv0 32)))) (INV1 M I C D J1 K1 G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)) (S (_ BitVec 32)) (T (_ BitVec 32)) (U (_ BitVec 32)) (V (_ BitVec 32)) (W (_ BitVec 32)) (X (_ BitVec 32)) (Y (_ BitVec 32)) (Z (_ BitVec 32)) (A1 (_ BitVec 32)) (B1 (_ BitVec 32)) (C1 (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd (bvadd I (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (= (bvadd D (_ bv1 32)) F)) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) K) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) K)) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) J)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) M) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) M)) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd P (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (not (bvsge (bvadd Q (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Q) (bvadd R (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) R) (bvadd S (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) S) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) S)) (_ bv0 32))) (bvsge (bvadd T (bvmul (bvneg (_ bv10 32)) R)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) T) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) T)) (_ bv0 32))) (bvsge (bvadd U (bvmul (bvneg (_ bv10 32)) Q)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) U) (bvadd V (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) V) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) V)) (_ bv0 32))) (bvsge (bvadd W (bvmul (bvneg (_ bv10 32)) U)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) W) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) W)) (_ bv0 32))) (bvsge (bvadd X (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) X) (bvadd Y (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Y) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) Y)) (_ bv0 32))) (bvsge (bvadd Z (bvmul (bvneg (_ bv10 32)) X)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Z) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) Z)) (_ bv0 32))) (bvsge (bvadd A1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A1) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) A1)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv100 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd L (bvneg (_ bv1 32))) (_ bv0 32))) (not (= B1 (_ bv0 32)))) (INV1 L I C D B1 C1 G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd I (_ bv1 32)) B) (= (bvmul (bvneg (_ bv1 32)) E) (_ bv0 32))) (= (bvadd D (_ bv1 32)) F)) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd J (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (not (bvsge (bvadd K (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) K) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd J (bvmul (bvneg (_ bv10 32)) K)) (_ bv0 32))) (bvsge (bvadd (bvsub (_ bv100 32) C) (bvneg (_ bv1 32))) (_ bv0 32))) (not (bvsge (bvadd (bvsub (_ bv10 32) C) (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd J (bvneg (_ bv1 32))) (_ bv0 32))) (not (= L (_ bv0 32)))) (INV1 J I C D L M G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (= (bvadd I (_ bv1 32)) B) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd J (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (not (bvsge (bvadd K (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) K) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd J (bvmul (bvneg (_ bv10 32)) K)) (_ bv0 32))) (bvsge (bvadd J (bvneg (_ bv1 32))) (_ bv0 32))) (= E (_ bv0 32))) (INV1 J I C D E F G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)) (S (_ BitVec 32)) (T (_ BitVec 32)) (U (_ BitVec 32)) (V (_ BitVec 32)) (W (_ BitVec 32)) (X (_ BitVec 32)) (Y (_ BitVec 32)) (Z (_ BitVec 32)) (A1 (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd (bvadd I (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) B) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) K) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) K)) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) J)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) M) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) M)) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd O (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd P (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (not (bvsge (bvadd Q (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Q) (bvadd R (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) R) (bvadd S (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) S) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) S)) (_ bv0 32))) (bvsge (bvadd T (bvmul (bvneg (_ bv10 32)) R)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) T) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) T)) (_ bv0 32))) (bvsge (bvadd U (bvmul (bvneg (_ bv10 32)) Q)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) U) (bvadd V (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) V) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) V)) (_ bv0 32))) (bvsge (bvadd W (bvmul (bvneg (_ bv10 32)) U)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) W) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) W)) (_ bv0 32))) (bvsge (bvadd X (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) X) (bvadd Y (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Y) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) Y)) (_ bv0 32))) (bvsge (bvadd Z (bvmul (bvneg (_ bv10 32)) X)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Z) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) Z)) (_ bv0 32))) (bvsge (bvadd A1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A1) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) A1)) (_ bv0 32))) (bvsge (bvadd L (bvneg (_ bv1 32))) (_ bv0 32))) (= E (_ bv0 32))) (INV1 L I C D E F G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)) (Q (_ BitVec 32)) (R (_ BitVec 32)) (S (_ BitVec 32)) (T (_ BitVec 32)) (U (_ BitVec 32)) (V (_ BitVec 32)) (W (_ BitVec 32)) (X (_ BitVec 32)) (Y (_ BitVec 32)) (Z (_ BitVec 32)) (A1 (_ BitVec 32)) (B1 (_ BitVec 32)) (C1 (_ BitVec 32)) (D1 (_ BitVec 32)) (E1 (_ BitVec 32)) (F1 (_ BitVec 32)) (G1 (_ BitVec 32)) (H1 (_ BitVec 32)) (I1 (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd (bvadd (bvadd I (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) (_ bv1 32)) B) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) K) (bvadd L (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) L) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) L)) (_ bv0 32))) (bvsge (bvadd N (bvmul (bvneg (_ bv10 32)) K)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) J)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd P (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (bvsge (bvadd Q (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Q) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) Q)) (_ bv0 32))) (bvsge (bvadd R (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) R) (bvadd S (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) S) (bvadd T (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) T) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) T)) (_ bv0 32))) (bvsge (bvadd U (bvmul (bvneg (_ bv10 32)) S)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) U) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) U)) (_ bv0 32))) (bvsge (bvadd V (bvmul (bvneg (_ bv10 32)) R)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) V) (bvadd W (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) W) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) W)) (_ bv0 32))) (bvsge (bvadd X (bvmul (bvneg (_ bv10 32)) V)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) X) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) X)) (_ bv0 32))) (bvsge (bvadd Y (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Y) (bvadd Z (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) Z) (bvadd A1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) A1)) (_ bv0 32))) (bvsge (bvadd B1 (bvmul (bvneg (_ bv10 32)) Z)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) B1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) B1)) (_ bv0 32))) (bvsge (bvadd C1 (bvmul (bvneg (_ bv10 32)) Y)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) C1) (bvadd D1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) D1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) D1)) (_ bv0 32))) (bvsge (bvadd E1 (bvmul (bvneg (_ bv10 32)) C1)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) E1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) E1)) (_ bv0 32))) (bvsge (bvadd F1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) F1) (bvadd G1 (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) G1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) G1)) (_ bv0 32))) (bvsge (bvadd H1 (bvmul (bvneg (_ bv10 32)) F1)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) H1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) H1)) (_ bv0 32))) (bvsge (bvadd I1 (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) I1) (bvadd M (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd M (bvmul (bvneg (_ bv10 32)) I1)) (_ bv0 32))) (bvsge (bvadd M (bvneg (_ bv1 32))) (_ bv0 32))) (= E (_ bv0 32))) (INV1 M I C D E F G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)) (I (_ BitVec 32)) (J (_ BitVec 32)) (K (_ BitVec 32)) (L (_ BitVec 32)) (M (_ BitVec 32)) (N (_ BitVec 32)) (O (_ BitVec 32)) (P (_ BitVec 32)))(=> (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvadd (bvadd I (_ bv1 32)) (_ bv1 32)) B) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd J (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) J) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) J)) (_ bv0 32))) (bvsge (bvadd L (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) L) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) L)) (_ bv0 32))) (not (bvsge (bvadd M (bvneg (_ bv1 32))) (_ bv0 32)))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) M) (bvadd N (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) N) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) N)) (_ bv0 32))) (bvsge (bvadd O (bvmul (bvneg (_ bv10 32)) M)) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) O) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) O)) (_ bv0 32))) (bvsge (bvadd P (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) P) (bvadd K (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd K (bvmul (bvneg (_ bv10 32)) P)) (_ bv0 32))) (bvsge (bvadd K (bvneg (_ bv1 32))) (_ bv0 32))) (= E (_ bv0 32))) (INV1 K I C D E F G H)) (= G H)) (INV1 A B C D E F G H))))
(assert (not (exists ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)) (H (_ BitVec 32)))(and (and (and (and (not (= A B)) (not (bvsge (bvadd C (bvneg (_ bv1 32))) (_ bv0 32)))) (= D (_ bv0 32))) (INV1 C A E F D B G H)) (= G H)))))
(assert (forall ((A (_ BitVec 32)) (B (_ BitVec 32)) (C (_ BitVec 32)) (D (_ BitVec 32)) (E (_ BitVec 32)) (F (_ BitVec 32)) (G (_ BitVec 32)))(=> (and (and (and (and (and (and (= (bvmul (bvneg (_ bv1 32)) B) (bvneg (_ bv1 32))) (= (bvmul (bvneg (_ bv1 32)) D) (bvneg (_ bv1 32)))) (= (bvmul (bvneg (_ bv1 32)) E) (bvneg (_ bv1 32)))) (= (bvmul (bvneg (_ bv1 32)) F) (_ bv1 32))) (bvsge (bvadd (bvsub (bvmul (_ bv10 32) A) (bvadd G (bvneg (_ bv10 32)))) (bvneg (_ bv1 32))) (_ bv0 32))) (bvsge (bvadd G (bvmul (bvneg (_ bv10 32)) A)) (_ bv0 32))) (= G C)) (INV1 A B C D E F G C))))
(check-sat)
